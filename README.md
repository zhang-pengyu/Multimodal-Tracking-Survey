# Multimodal Tracking Survey
A comprehensive survey on multimodal tracking [[Paper]](https://arxiv.org/pdf/2012.04176.pdf), including RGB-T and RGB-D tracking methods. This list will be long-term updating. If your related paper is missing in this review, feel free to contact [pyzhang@mail.dlut.edu.cn](mailto:pyzhang@mail.dlut.edu.cn).
![alt text](https://github.com/zhang-pengyu/Multimodal_tracking_survey/blob/master/Paper_list_with_taxonomy.png)

# Citation
If our paper and repositority are helpful for your work, please cite us,

@article{Zhang_Arxiv20_MM_tracking_survey,\
author = {Pengyu Zhang and Dong Wang and Huchuan Lu},\
title = {Multi-modal Visual Tracking: Review and Experimental Comparison},\
journal={arXiv preprint arXiv:2012.04176},\
year={2020}\
} 

# Multimodal Tracking List
 ## RGB-D tracking
 ### 2020
 * **WCO**: Weichun Liu, Xiaoan Tang, Chengling Zhao. Robust RGBD Tracking via Weighted Convlution Operators. In _Sensors_ 20(8), 2020. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8950173/)
 ### 2019
 * **3DMS**: Alexander Gutev, Carl James Debono. Exploiting Depth Information to Increase Object Tracking Robustness. In _ICST_ 2019. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8861628/)
 * **OTR**: Ugur Kart, Alan Lukezic, Matej Kristan, Joni-Kristian Kamarainen, Jiri Matas. Object Tracking by Reconstruction with View-Specific Discriminative Correlation Filters. In _CVPR_ 2019. [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Kart_Object_Tracking_by_Reconstruction_With_View-Specific_Discriminative_Correlation_Filters_CVPR_2019_paper.pdf) [[Code]](https://github.com/ugurkart/OTR)
 * **TACF**: Yangliu Kuai, Gongjian Wen, Dongdong Li, Jingjing Xiao. Target-Aware Correlation Filter Tracking in RGBD Videos. In _Sensors_ 19(20), 2019. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8752050)
 * **CA3DMS**: Ye Liu, Xiao-Yuan Jing, Jianhui Nie, Hao Gao, Jun Liu, Guo-Ping Jiang. Context-Aware Three-Dimensional Mean-Shift With Occlusion Handling for Robust Object Tracking in RGB-D Videos. In _TMM_ 21(3), 2019. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8425768)
 * **OTOD**:  Yujun Xie, Yao Lu, Shuang Gu. RGB-D Object Tracking with Occlusion Detection. In _CIS_ 2019. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9023755)

 ### 2018
* **CSR-rgbd**: Uğur Kart, Joni-Kristian Kämäräinen, Jiří Matas. How to Make an RGBD Tracker? In _ECCV Workshop_ 2018. [[Paper]](https://link.springer.com/chapter/10.1007/978-3-030-11009-3_8) [[Code]](http://tracking.cs.princeton.edu/)
* **DMDCF**: Uğur Kart, Joni-Kristian Kämäräinen, Jiří Matas, Lixin Fan, Francesco Cricri. Depth Masked Discriminative Correlation Filter. In _ICPR_ 2018. [[Paper]](https://arxiv.org/pdf/1802.09227.pdf)
* **SEOH**: Jiaxu Leng, Ying Liu. Real-Time RGB-D Visual Tracking With ScaleEstimation and Occlusion Handling. In _Access_ (6), 2018. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353501)
* **ARDM**: Jingjing Xiao, Rustam Stolkin, Yuqing Gao, Aleš Leonardis. Robust Fusion of Color and Depth Data for RGB-D Target Tracking Using Adaptive Range-Invariant Depth Models and Spatio-Temporal Consistency Constraints. In _TC_ 48(8) 2018. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8026575) [[Code]](https://github.com/shine636363/RGBDtracker)
* **OACPF**: Yayu Zhai, Ping Song, Zonglei Mou, Xiaoxiao Chen, Xiongjun Liu. Occlusion-Aware Correlation Particle FilterTarget Tracking Based on RGBD Data. In _Access_ (6), 2018. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463446)
* **CCF**: Guanqun Li, Lei Huang, Peichang Zhang, Qiang Li, YongKai Huo. Depth Information Aided Constrained correlation Filter for Visual Tracking. In _GSKI_ 2018.
[[Paper]](https://iopscience.iop.org/article/10.1088/1755-1315/234/1/012005)
* **RTKCF**: Han Zhang, Meng Cai, Jianxun Li.  A Real-time RGB-D tracker based on KCF. In _CCDC_ 2018. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8407972)
 
 ### 2017
 * **ROTSL**: Zi-ang Ma, Zhi-yu Xiang. Robust Object Tracking with RGBD-based Sparse Learning. In _ITEE_ (18), 2017. [[Paper]](https://link.springer.com/article/10.1631/FITEE.1601338)
 ### 2016
 * **DLST**:  Ning An, Xiao-Guang Zhao, Zeng-Guang Hou.  Online RGB-D Tracking via Detection-Learning-Segmentation. In _ICPR_ 2016. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7899805)
 * **DSKCF**: Sion Hannuna, Massimo Camplani, Jake Hall, Majid Mirmehdi, Dima Damen, Tilo Burghardt, Adeline Paiement, Lili Tao. DS-KCF: A Real-time Tracker for RGB-D Data. In _RTIP_ (16), 2016. [[Paper]](https://link.springer.com/content/pdf/10.1007/s11554-016-0654-3.pdf) [[Code]](https://github.com/mcamplan/DSKCF_JRTIP2016)
 * **3DT**: Adel Bibi, Tianzhu Zhang, Bernard Ghanem. 3D Part-Based Sparse Tracker with Automatic Synchronization and Registration. In _CVPR_ 2016. [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Bibi_3D_Part-Based_Sparse_CVPR_2016_paper.pdf) [[Code]](https://github.com/adelbibi/3D-Part-Based-Sparse-Tracker-with-Automatic-Synchronization-and-Registration)
 * **OAPF**: Kourosh Meshgia, Shin-ichi Maedaa, Shigeyuki Obaa, Henrik Skibbea, Yu-zhe Lia, Shin Ishii. Occlusion Aware Particle Filter Tracker to Handle Complex and Persistent Occlusions. In _CVIU_ (150), 2016. [[Paper]](http://ishiilab.jp/member/meshgi-k/files/ai/prl14/OAPF.pdf)
 ### 2015
  * **ISOD**: Yan Chen, Yingju Shen, Xin Liu, Bineng Zhong. 3D Object Tracking via Image Sets and Depth-Based Occlusion Detection. In _SP_ (112), 2015. [[Paper]](https://www.sciencedirect.com/science/article/pii/S0165168414004204)
  * **DSOH**: Massimo Camplani, Sion Hannuna, Majid Mirmehdi, Dima Damen, Adeline Paiement, Lili Tao, Tilo Burghardt. Real-time RGB-D Tracking with Depth Scaling Kernelised Correlation Filters and Occlusion Handling. In _BMVC_, 2015. [[Paper]](https://core.ac.uk/reader/78861956) [[Code]](https://github.com/mcamplan/DSKCF_BMVC2015)
  * **DOHR**: Ping Ding, Yan Song. Robust Object Tracking Using Color and Depth Images with a Depth Based Occlusion Handling and Recovery. In _FSKD_, 2015. [[Paper]](https://ieeexplore.ieee.org/document/7382068)
  * **CDG**: Huizhang Shi, Changxin Gao, Nong Sang. Using Consistency of Depth Gradient to Improve Visual Tracking in RGB-D sequences. In _CAC_, 2015. [[Paper]](https://ieeexplore.ieee.org/document/7382555)
  * **OL3DC**: Bineng Zhong, Yingju Shen, Yan Chen, Weibo Xie, Zhen Cui, Hongbo Zhang, Duansheng Chen ,Tian Wang, Xin Liu, Shujuan Peng, Jin Gou, Jixiang Du, Jing Wang, Wenming Zheng. Online Learning 3D Context for Robust Visual Tracking. In _Neurocomputing_ (151), 2015. [[Paper]](https://www.sciencedirect.com/science/article/pii/S0925231214013757)
  ### 2014
  * **MCBT**: Qi Wang, Jianwu Fang, Yuan Yuan. Multi-Cue Based Tracking. In _Neurocomputing_ (131), 2014. [[Paper]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.700.8771&rep=rep1&type=pdf)
  ### 2012
 * **AMCT**: Germán Martín García, Dominik Alexander Klein, Jörg Stückler, Simone Frintrop, Armin B. Cremers. Adaptive Multi-cue 3D Tracking of Arbitrary Objects. In _JDOS_, 2012. [[Paper]](https://link.springer.com/chapter/10.1007/978-3-642-32717-9_36)
  ### Datasets
  * **PTB**: Shuran Song, Jianxiong Xiao. Tracking Revisited using RGBD Camera: Unified Benchmark and Baselines. In _ICCV_, 2013. [[Paper]](https://vision.princeton.edu/projects/2013/tracking/paper.pdf) [[Project]](https://tracking.cs.princeton.edu/index.html) [[Dataset]](https://tracking.cs.princeton.edu/dataset.html)
  * **STC**: Jingjing Xiao, Rustam Stolkin, Yuqing Gao, Aleš Leonardis. Robust Fusion of Color and Depth Data for RGB-D Target Tracking Using Adaptive Range-Invariant Depth Models and Spatio-Temporal Consistency Constraints. In _TC_ 48(8) 2018. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8026575) [[Dataset]](https://beardatashare.bham.ac.uk/dl/fiVnhJRjkyNN8QjSAoiGSiBY/RGBDdataset.zip)
  * **CDTB**:Alan Lukezic, Ugur Kart, Jani Kapyla, Ahmed Durmush, Joni-Kristian Kamarainen, Jiri Matas, Matej Kristan. CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark. In _ICCV_, 2019. [[Paper]](https://arxiv.org/pdf/1907.00618.pdf) [[Project]](https://www.vicos.si/Projects/CDTB) [[Dataset]](https://www.votchallenge.net/vot2019/dataset.html)
  *  **DepthTrack**: Song Yan, Jinyu Yang, Jani Käpylä, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen. DepthTrack : Unveiling the Power of RGBD Tracking. In ArXiv, 2021. [[Paper]](https://arxiv.org/abs/2108.13962)
  
## RGB-T Tracking
### 2021

* **DFNet**: Jingchao Peng, Haitao Zhao and Zhengwei Hu. Dynamic Fusion Network for RGBT Tracking. In ArXiv, 2021. [[Paper]](https://arxiv.org/pdf/2109.07662.pdf)
* **ADRNet**: Pengyu Zhang, DongWang, Huchuan Lu and Xiaoyun Yang. Learning Adaptive Attribute-Driven Representation for Real-Time RGB-T Tracking. In IJCV, 2021. [[Paper]](https://link.springer.com/article/10.1007/s11263-021-01495-3) [[Code]](https://github.com/zhang-pengyu/ADRNet)
* **SiamCDA**: Tianlu Zhang, Xueru Liu, Qiang Zhang and Jungong Han. SiamCDA: Complementarity-and distractor-aware RGB-T tracking based on Siamese network. In TCSVT, 2021. [[Paper]](https://ieeexplore.ieee.org/document/9399460)
* **SiamIVFN**: Jingchao Peng, Haitao Zhao, Zhengwei Hu, Yi Zhuang and Bofan Wang. Siamese Infrared and Visible light fusion network for RGB-T Tracking. In ArXiv, 2021. [[Paper]](https://arxiv.org/pdf/2103.07302.pdf)
* **JMMAC**: Pengyu Zhang, Jie Zhao, Chunjuan Bo, Dong Wang, Huchuan Lu, Xiaoyun Yang. Jointly Modeling Motion and Appearance Cues for Robust RGB-T Tracking. In TIP(30), 2021. [[Paper]](https://ieeexplore.ieee.org/document/9364880) [[Code]](https://github.com/zhang-pengyu/JMMAC)
### 2020
* **MFGNet**: Xiao Wang, Xiujun Shu, Shiliang Zhang, Bo Jiang, Yaowei Wang, Yonghong Tian, Feng Wu. Dynamic Modality-Aware Filter Generation for RGB-T Tracking. In ArXiv 2020.[[Project]](https://sites.google.com/view/mfgrgbttrack/)
* **DMCNet**: Andong Lu, Cun Qian, Chenglong Li, Jin Tang, and Liang Wang. Duality-Gated Mutual Condition Network forRGBT Tracking. In ArXiv, 2020. [[Paper]](https://arxiv.org/pdf/2011.07188.pdf)
* **CAT**: Chenglong Li, Lei Liu, Andong Lu, Qing Ji, Jin Tang. Challenge-aware RGBT tracking. In _ECCV_, 2020. [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123670222.pdf)
* **CMPP**: Chaoqun Wang, Chunyan Xu, Zhen Cui, Ling Zhou, Tong Zhang, Xiaoya Zhang, Jian Yang. Cross-modal pattern-propagation for RGB-T tracking. In _CVPR_, 2020. [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Cross-Modal_Pattern-Propagation_for_RGB-T_Tracking_CVPR_2020_paper.pdf)
* **MaCNet**: Hui Zhang, Lei Zhang, Li Zhuo, Jing Zhang. Object Tracking in RGB-T Videos Using Modal-Aware Attention Network and Competitive Learning. In _Sensors_ 20(2), 2020. [[Paper]](https://www.mdpi.com/1424-8220/20/2/393)
### 2019 
* **DAPNet**：Yabin Zhu, Chenglong Li, Bin Luo, Jin Tang, Xiao Wang. Dense Feature Aggregation and Pruning for RGBT Tracking. In _ACM MM_, 2019. [[Paper]](https://arxiv.org/pdf/1907.10451.pdf)
* **HTF**: Chengwei Luo, Bin Sun, Ke Yang, Taoran Lu, Wei-Chang Yeh. Thermal Infrared and Visible Sequences Fusion Tracking based on a Hybrid Tracking Framework with Adaptive Weighting Scheme. In _IPT_ (99), 2019. [[Paper]](https://www.sciencedirect.com/science/article/pii/S1350449519300258)
* **LMCFT**: Xiangyuan Lan, Mang Ye, Rui Shao, Bineng Zhong, Pong C. Yuen, Huiyu Zhou. Learning Modality-Consistency Feature Templates: A Robust RGB-Infrared Tracking System. In _TIE_ 66(12), 2019. [[Paper]](http://archiv.nexgam.pcsg5.pcsg-server.de/paper_ir_tracker/papers/08643077.pdf)
* **MANet**: Chenglong Li, Andong Lu, Aihua Zheng, Zhengzheng Tu, Jin Tang. Multi-Adapter RGBT Tracking. In  _ICCV Workshop_, 2019. [[Paper]](https://arxiv.org/abs/1907.07485)
* **TODA**: Rui Yang, Yabin Zhu, Xiao Wang, Chenglong Li, Jin Tang. Learning Target-Oriented Dual Attention for Robust RGB-T Tracking. In _ICIP_, 2019.[[Paper]](https://arxiv.org/pdf/1908.04441.pdf)
* **DAFNet**: Yuan Gao, Chenglong Li, Yabin Zhu, Jin Tang, Tao He, Futian Wang. Deep Adaptive Fusion Network for High Performance RGBT Tracking. In _ICCV Workshop_ 2019. [[Paper]](https://openaccess.thecvf.com/content_ICCVW_2019/papers/VISDrone/Gao_Deep_Adaptive_Fusion_Network_for_High_Performance_RGBT_Tracking_ICCVW_2019_paper.pdf)
* **DiMP-RGBT**: Lichao Zhang, Martin Danelljan, Abel Gonzalez-Garcia, Joost van de Weijer, Fahad Shahbaz Khan. Multi-Modal Fusion for End-to-End RGB-T Tracking. In _ICCV Workshop_, 2019. [[Paper]](https://arxiv.org/pdf/1908.11714.pdf)
* **ONMF**: Xiangyuan Lan, Mang Ye, Rui Shao, Bineng Zhong, Deepak Kumar Jain, Huiyu Zhou. Online Non-Negative Multi-Modality Feature Template Learning for RGB-Assisted Infrared Tracking. In Access (7), 2019. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8713854)
* **CMCF**: Sulan Zhai, Pengpeng Shao, Xinyan Liang, Xin Wang. Fast RGB-T Tracking via Cross-Modal Correlation Filters. In Neurocomputing (334), 2019. [[Paper]](https://www.sciencedirect.com/science/article/pii/S0925231219300347)
### 2018
* **RCDL**: Xiangyuan Lan, Mang Ye, Shengping Zhang, Pong C. Yuen. Robust Collaborative Discriminative Learning for RGB-Infrared Tracking. In AAAI, 2018. [[Paper]](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16878/16289)
* **MSR**: Xiangyuan Lan, Mang Ye, Shengping Zhang, Huiyu Zhou, Pong C. Yuen. Modality-correlation-aware sparse representation for RGB-infrared object tracking. In _PRL_(130), 2018.
* **CMR**: Chenglong Li, Chengli Zhu, Yan Huang, Jin Tang, Liang Wang. Cross-Modal Ranking with Soft Consistency and Noisy Labels for Robust RGB-T Tracking. In _ECCV_, 2018. [[Paper]](https://openaccess.thecvf.com/content_ECCV_2018/papers/Chenglong_Li_Cross-Modal_Ranking_with_ECCV_2018_paper.pdf)
* **RMR**: Chenglong Li, Chengli Zhu, Shaofei Zheng, Bin Luo, Jing Tang. Two-Stage Modality-Graphs Regularized Manifold Ranking for RGB-T Tracking. In _SPIC_ (68), 2018. [[Paper]](https://www.sciencedirect.com/science/article/pii/S0923596518304892)
* **LGMG**:Chenglong Li, Chengli Zhu, Jian Zhang, Bin Luo, Xiaohao Wu, Jin Tang. Learning Local-Global Multi-Graph Descriptors for RGB-T Object Tracking. In _TCSVT_ 29(10), 2018. [[Paper]](https://ieeexplore.ieee.org/abstract/document/8485393)
* **MDNet-RGBT**: Xingming Zhang, Xuehan Zhang, Xuedan Du, Xiangming Zhou, Jun Yin. Learning Multi-domain Convolutional Network for RGB-T Visual Tracking. In _CISP_, 2018. [[Paper]](https://ieeexplore.ieee.org/document/8633180)
* **FTSNet**: Chenglong Li, Xiaohao Wu, Nan Zhao, Xiaochun Cao, Jin Tang. Fusing Two-Stream Convolutional Neural Networks for RGB-T Object
Tracking. In Neurocomputing (281), 2018. [[Paper]](https://www.sciencedirect.com/science/article/pii/S0925231217318271)
* **CSCF**: Yulong Wang, Chenglong Li, Jin Tang, and Dengdi Sun. Learning Collaborative Sparse Correlation Filter for Real-Time Multispectral Object Tracking. In _BICS_, 2018. [[Paper]](https://link.springer.com/content/pdf/10.1007%2F978-3-030-00563-4_45.pdf)
### 2017
* **SGT**: Chenglong Li, Nan Zhao, Yijuan Lu, Chengli Zhu, Jin Tang. Weighted Sparse Representation Regularized Graph Learning
for RGB-T Object Tracking. In _ACM MM_, 2017. [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3123266.3123289)
* **MLSR**: Chenglong Li, Xiang Sun, Xiao Wang, Lei Zhang, Jin Tang. Grayscale-Thermal Object Tracking via Multitask Laplacian Sparse Representation. In _TSMCS_ 47(4), 2017. [[Paper]](https://ieeexplore.ieee.org/abstract/document/7822984)
### 2016
* **RT-LSR**: Chenglong Li, Shiyi Hu, Sihan Gao, Jin Tang. Real-Time Grayscale-Thermal Tracking via Laplacian Sparse Representation. In _MMM_, 2016. [[Paper]](https://link.springer.com/content/pdf/10.1007%2F978-3-319-27674-8_6.pdf)
* **CSR**: Chenglong Li, Hui Cheng, Shiyi Hu, Xiaobai Liu, Jin Tang, Liang Lin. Learning Collaborative Sparse Representation for Grayscale-Thermal Tracking. In _TIP_ 25(12), 2016.[[Paper]](http://linliang.net/wp-content/uploads/2017/07/TIP-LCSR.pdf)
### 2012
* **JSR**: Huaping Liu, Fuchun Sun. Fusion Tracking in Color and Infrared Images using Joint Sparse Representation. INIS 55(3), 2012. [[Paper]](https://link.springer.com/content/pdf/10.1007/s11432-011-4536-9.pdf)
### 2011
* **L1-PF**: Yi Wu, Erik Blasch, Genshe Chen, Li Bai, Haibin Ling. Multiple Source Data Fusion via Sparse Representation for Robust Visual Tracking. IN _ICIF_, 2011. [[Paper]](https://ieeexplore.ieee.org/document/5977451)
### 2008
* **PGM**: Siyue Chen, Wenjie Zhu, Henry Leung. Thermo-Visual Video Fusion Using Probabilistic Graphical Model for Human Tracking. In _ISCS_, 2008. [[Paper]](https://ieeexplore.ieee.org/abstract/document/4541820)
* **MST**: Ciarán Ó Conaire, Noel E. O’Connor, Alan Smeaton. Thermo-Visual Feature Fusion for Object Tracking using Multiple Spatiogram Trackers. In MVA (19), 2008. [[Paper]](https://link.springer.com/content/pdf/10.1007/s00138-007-0078-y.pdf)
### 2007
* **PLF**: N. Cvejic, S. G. Nikolov, H. D. Knowles, A. Łoza, A. Achim, D. R. Bull, C. N. Canagarajah. The Effect of Pixel-Level Fusion on Object Tracking in Multi-Sensor Surveillance Video. In _CVPR_, 2007. [[Paper]](https://ieeexplore.ieee.org/document/4270431)
### 2006
* **CFM**:C. 0 Conaire, N. E. O'Connor, E. Cooke, A. F. Smeaton. Comparison of Fusion Methods for Thermo-Visual Surveillance Tracking. In _ICIF_ 2006. [[Paper]](http://doras.dcu.ie/226/1/ieee_fusion_2006.pdf)
### Dataset
* **OTCBVS**: James W. Davis, Vinay Sharma. Background-Subtraction using Contour-based Fusion of Thermal and Visible Imagery. In CVIU (106), 2007. [[Paper]](https://d1wqtxts1xzle7.cloudfront.net/32831799/cviu07.pdf?1390545493=&response-content-disposition=inline%3B+filename%3DBackground-subtraction_using_contour-bas.pdf&Expires=1596262131&Signature=JtwJEV53b7gHYRzMXKLVcS8X~IRI3afd7M4aVTURoQ-76XPVpJQrdZfUABDEOm~fUtg-vH8Hg0zMOSlEBHomSzacI9HzHtPT5g3DPls2AmCMS4LzG0GHecVlwjY8uMcIFSq7eXw5RBYWTe2XcBMjfKkT4WNZrEItnQ1L7pv97kRes6rdU2J7K6vUcNVc1OYOfGNcVXRZUbzAk2smXeEtKJeTOYu0W6Duj--DUONthg4wWqd7HJAQ9Y1z2qO4TsQSUWZIqveS9-LIzUtBLfc9YaB8YzWlghUeOdkBD0T46qrTYoLG~HL~sp3IOYGfdYcqJL2EHiyFKnOPdC3cP1Z~CA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA) [[Project]](http://vcipl-okstate.org/pbvs/bench/) [[Dataset]](http://vcipl-okstate.org/pbvs/bench/Data/03/download.html)
* **LITIV**: Atousa Torabi, Guillaume Massé, Guillaume-Alexandre Bilodeau. An Iterative Integrated Framework for Thermal–Visible Image Registration, Sensor Fusion, and People Tracking for Video Surveillance applications. In _CVIU_ (116), 2012. [[Paper]](https://reader.elsevier.com/reader/sd/pii/S1077314211002335?token=91D1798AF0E7450752443D7CF5516589CB162E742D08CAB23EAF15E4DEC5B090C569674BAC9EB64B2EC19125C508301E) [[Project]](https://www.polymtl.ca/litiv/en/codes-and-datasets) [[Code]](https://share.polymtl.ca/alfresco/service/api/path/content;cm:content/workspace/SpacesStore/Company%20Home/Sites/litiv-web/documentLibrary/Datasets/litiv2012_dataset.zip?a=true&guest=true)
* **GTOT**: Chenglong Li, Xiang Sun, Xiao Wang, Lei Zhang, Jin Tang. Grayscale-Thermal Object Tracking via Multitask Laplacian Sparse Representation. In _TIP_ 47(4), 2016. [[Paper]](https://ieeexplore.ieee.org/abstract/document/7822984) [[Dataset]](https://pan.baidu.com/s/1QNidEo-HepRaS6OIZr7-Cw)
* **RGBT210**: Chenglong Li, Nan Zhao, Yijuan Lu, Chengli Zhu, Jin Tang. Weighted Sparse Representation Regularized Graph Learning
for RGB-T Object Tracking. In _ACM MM_, 2017. [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3123266.3123289)
* **RGBT-234**: Chenglong Li, Xinyan Liang, Yijuan Lu, Nan Zhao, Jin Tang. RGB-T Object Tracking: Benchmark and Baseline. In _PR_ (96), 2019. [[Paper]](https://www.sciencedirect.com/science/article/pii/S0031320319302808) [[Project]](https://sites.google.com/view/ahutracking001/) [[Dataset]](https://drive.google.com/file/d/1ouNEptXOgRop4U7zYMK9zAp57SZ2XCNL/view)
* **VOT-RGBT**: Matej Kristan, Jiri Matas, Ales Leonardis _et al._ The Seventh Visual Object Tracking VOT2019 Challenge Results. In _ICCV Workshop_, 2019. [[Paper]](https://prints.vicos.si/publications/files/375) [[Project]](https://www.votchallenge.net/vot2019/index.html) [[Dataset]](https://www.votchallenge.net/vot2019/dataset.html)
* **LSS Dataset** Tianlu Zhang, Xueru Liu, Qiang Zhang, Jungong Han. SiamCDA: Complementarity-and distractor-aware RGB-T tracking based on Siamese network [[Project]](https://github.com/RaymondCover/LSS-Dataset)
* **LasHeR**: Chenglong Li, Wanlin Xue, Yaqing Jia, Zhichen Qu, Bin Luo, and Jin Tang. LasHeR: A Large-scale High-diversity Benchmark
for RGBT Tracking. In _ArXiV_. [[Paper]](https://arxiv.org/pdf/2104.13202.pdf) [[Project]](https://github.com/BUGPLEASEOUT/LasHeR)
